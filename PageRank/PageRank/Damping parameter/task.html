<h2 style="text-align: center;">Theory</h2>

<p>The system we just studied converged fairly quickly to the correct answer. Let's consider an extension to our micro-internet where things start to go wrong.</p>

<p>Say a new website is added to the micro-internet: George's Website. This website is linked to by FaceArea and only links to itself.</p>

<p style="text-align: center;"><img alt="" height="310" src="https://lh3.googleusercontent.com/r1xbgtAu53_3aGUOTvDPQnBF-QBFLy5r0A2szBSS1hY8ssvEdPPjcSu9kC2zOZznxivHrWgViLc7AzTV1Zra8S32yYKgk2xnIPBvt1vj4ZLo03Bfuxl9ywFQUz-q5IbcSKNYADf-" width="471"></p>

<p>Intuitively, only FaceArea, which is in the bottom half of the page rank, links to this website amongst the two others it links to, so we might expect George's site to have a correspondingly low PageRank score.</p>

<p>Build the new L matrix for the expanded micro-internet, and use Power-Iteration on the Procrastinating Pat vector. See what happens...</p>

<p>Complete the matrix L2 below. After completing it print the L2 row-by-row with a precision of 3 decimal places.</p>

<pre><code class="language-python"># We'll call this one L2, to distinguish it from the previous L.
L2 = np.array([
    [0,   1/2, 1/3, 0, 0,   ???, 0 ],
    [1/3, 0,   0,   0, 1/2, ???, 0 ],
    [1/3, 1/2, 0,   1, 0,   ???, 0 ],
    [1/3, 0,   1/3, 0, 1/2, ???, 0 ],
    [0,   0,   0,   0, 0,   ???, 0 ],
    [0,   0,   1/3, 0, 0,   ???, 0 ],
    [0,   0,   0,   0, 0,   ???, 1 ]
])</code></pre>

<p>Calculate page rank with the Power-Iteration method which you implemented in the previous stage. Apply the iteration method so that the difference between the <span class="math-tex">\(r^{(i)}\)</span> and <span class="math-tex">\(r^{(i+1)}\)</span> is not bigger than 0.01 and print the vector with a precision of 3 decimal places.</p>

<p>That's no good! George seems to be taking all the traffic on the micro-internet, and somehow coming at the top of the PageRank. This behavior can be understood, because once a Pat gets to George's Website, they can't leave, as all links head back to George.</p>

<p>To combat this, we can add a small probability that the Procrastinating Pats don't follow any link on a webpage, but instead, visit a website on the micro-internet at random. We'll say the probability of them following a link is d and the probability of choosing a random website is therefore 1−d . We can use a new matrix to work out where Pat's visit each minute.</p>

<p style="text-align: center;"><span class="math-tex">\(M = dL + \frac{1-d}{n}J\)</span></p>

<p>Where </p>

<p><strong>d</strong> is Damping Factor;</p>

<p><strong>M</strong> is a new matrix which adds the probability of a random visit to a page that the current page doesn’t contain links to.</p>

<p><strong>L</strong> is our old matrix.</p>

<p><strong>n</strong> is number of sites in micro-internet (dimension of matrix);</p>

<p>and <strong>J</strong> is matrix where every element is 1.</p>

<p> </p>

<p>To do arithmetic operations between matrices and numbers here are the methods:</p>

<p>To create a 7 by 7 matrix where every element is 1, you can use the <code class="language-python">np.ones((7,7))</code> method.</p>

<p>To multiply a matrix by a number (scalar, integer), you can use the familiar arithmetic operation. For example, you can multiply each element of matrix L by 0.5 this way:  <code class="language-python">L * 0.5</code></p>

<p>To add up the corresponding elements of matrices, use this simple formula:  <code class="language-python">A + B</code></p>

<p> </p>

<p>If <strong>d</strong> is one, we have the case we had previously, whereas if <strong>d</strong> is zero, we will always visit a random webpage and therefore all webpages will be equally likely and equally ranked. For this extension to work best, <strong>1−d</strong> should be somewhat small - though we won't go into a discussion about exactly how small.</p>

<p>From the mathematical perspective, we are adding a slight probability of jumping to a random website, without having a link to it on the current site. That probability is inversely related to the parameter <strong>d</strong>, in other words, the less <strong>d</strong> is, the higher the probability of jumping to a random page.</p>

<p>Now, calculate PageRank for the network using the Power-Iteration method with a damping parameter d = 0.5 and precision 0.01. Print the resulting PageRank.</p>

<p>This is certainly better, the PageRank gives sensible numbers for the Procrastinating Pats that end up on each webpage. This method still predicts George has a high ranking webpage, however. This could be seen as a consequence of using a small network. We could also get around the problem by not counting self-links when producing the L matrix (an if a website has no outgoing links, make it link to all websites equally). We won't look further down this route, as this is in the realm of improvements to PageRank, rather than eigenproblems.</p>

<p>You are now in a good position, having gained an understanding of PageRank, to produce your own code to calculate the PageRank of a website with thousands of entries.</p>

<p>Good Luck!</p>

<h2 style="text-align: center;">Example</h2>

<p>Example of your program output for this stage</p>

<pre><code class="language-no-highlight">0.000 0.500 0.333 0.000 0.000 100.000 0.000
0.333 0.000 0.000 0.000 0.500 100.000 0.000
0.333 0.500 0.000 1.000 0.000 100.000 0.000
0.333 0.000 0.333 0.000 0.500 100.000 0.000
0.000 0.000 0.000 0.000 0.000 100.000 0.000
0.000 0.000 0.333 0.000 0.000 100.000 0.000
0.000 0.000 0.000 0.000 0.000 100.000 1.000

15.000
15.000
15.000
15.000
15.000
25.000
35.000

15.000
15.000
15.000
15.000
15.000
25.000
35.000
</code></pre>